{
 "metadata": {
  "name": "",
  "signature": "sha256:733e72e0eaed7c2d9118f0b670b6179d0cb3878479df26f4ebc0ac2db30ddf08"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load otto_Pikki.py\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%writefile otto_Pikki.py\n",
      "%matplotlib inline\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.utils import shuffle\n",
      "#from sklearn.ensemble import RandomForestClassifier ,GradientBoostingClassifier\n",
      "#from sklearn.feature_selection import SelectKBest\n",
      "#from sklearn.feature_selection import chi2, f_classif\n",
      "#from sklearn.tree import DecisionTreeClassifier\n",
      "#from sklearn.pipeline import Pipeline\n",
      "#from sklearn.lda import LDA\n",
      "#from sklearn.neural_network import BernoulliRBM\n",
      "#from sklearn.svm import LinearSVC\n",
      "from sklearn import cross_validation\n",
      "#from sklearn.linear_model import (RandomizedLasso, lasso_stability_path,\n",
      "                           #       LassoLarsCV)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "from matplotlib import pyplot as plt\n",
      "\n",
      "def sigmoid(x):\n",
      "    print('XXXX')\n",
      "    y = 1/(1+np.exp(x))\n",
      "    return y\n",
      "import time\n",
      "\n",
      "def load_data(train=True):\n",
      "    \"\"\"loads Data.\n",
      "    train == True means training data which has y values\n",
      "    train == False means testing (=pleasePredict) data, which only has X values\n",
      "    \"\"\"\n",
      "#test set\n",
      "    start = time.clock()\n",
      "\n",
      "    if train==False:\n",
      "        #dp = '/home/thomas/Desktop/OttoChallenge/test.csv'\n",
      "        dp ='test.csv'\n",
      "        df = pd.read_csv(dp)\n",
      "        X = df.values.astype(np.float32)[:,1:]\n",
      "        return X\n",
      "#train set\n",
      "    else:\n",
      "        #dp = '/home/thomas/Desktop/OttoChallenge/train.csv'\n",
      "        dp = 'train.csv'\n",
      "        df = pd.read_csv(dp)\n",
      "        X = df[df.columns[:-1]].values.astype(np.float32)[:,1:]\n",
      "        y = df.target\n",
      "        y =y.apply(lambda X: int(X[-1])).values\n",
      "        y = y.astype(np.int32)\n",
      "        X, y = shuffle(X, y)\n",
      "        #print(X.shape,y.shape)\n",
      "        end = time.clock()\n",
      "        print(end-start)\n",
      "\n",
      "        return X,y\n",
      "def make_dummies(df,df_2):\n",
      "    num_train = df.shape[0]\n",
      "    df['train'] = 1\n",
      "    df_2['train'] = 0\n",
      "    df_2.index += num_train\n",
      "    df = df.append(df_2)\n",
      "    var_list = list(df.columns)\n",
      "    for name in var_list:\n",
      "        df_tmp = pd.get_dummies(df[name],prefix=name)\n",
      "        df.drop(name,axis=1)\n",
      "\n",
      "        df = df.join(df_tmp)\n",
      "    df_train = df[df['train']==1]\n",
      "    \n",
      "    df_test = df[df['train']==0]\n",
      "    \n",
      "    X = df_train.values.astype(np.float32)\n",
      "    X_test = df_test.values.astype(np.float32)\n",
      "    return X,X_test\n",
      "    \n",
      "\n",
      "def generate_features(X, shuffle_data = False, which_slice = 0,how_many_slices = 1,dummies = False):\n",
      "    \"\"\"generates features from np.array X.\n",
      "    most of them aren't that great but give a little boost in performance. Last 93 features are interesting,\n",
      "    computed from a correlation matrix.\n",
      "    \n",
      "    shuffle Data shuffles the data,\n",
      "    how many slices specifies by what number the data should be divided\n",
      "    which slice then states which part of the data should be used (mind the 0)\n",
      "    dummes keyword doesn't work yet.\n",
      "    \"\"\"\n",
      "    start = time.clock()\n",
      " \n",
      "    \n",
      "    df_X = pd.DataFrame(X)\n",
      "    if dummies ==True:\n",
      "        print('dummies')\n",
      "        \n",
      "    df_tmp = df_X.cumsum(axis=1)\n",
      "    \n",
      "    df_tmp_2 = df_X.cumprod(axis=1)\n",
      "    df_tmp_5 = df_X.cummax(axis=1)\n",
      "\n",
      "    df_tmp_6 = df_X.cummin(axis=1)\n",
      "    df_tmp_3 = df_X**2\n",
      "    df_tmp_4 =     df_X.T.diff(2).T.dropna(axis=1,how='any')\n",
      "#df_X**3\n",
      "    df_tmp_7 = df_X.T.diff(1).T.dropna(axis=1,how='any')\n",
      "    df_tmp_8 = df_X**3\n",
      "    df_tmp_9 = df_X**5\n",
      "    df_tmp_10 = df_X - df_X.apply(np.mean,axis=0)#will this work?\n",
      "    df_test = pd.stats.moments.rolling_mean(df_X.T,window = 19,axis=1)\n",
      "    df_test = df_test.T.dropna(axis=1,how='any')\n",
      "\n",
      "    df_X['nonzero_sum'] = df_X.apply(np.count_nonzero,axis=1)\n",
      "   # df_X['binc'] = df_X.apply(np.unique,axis=1)\n",
      "    corr = df_X.corr()\n",
      "    df_tmp_11 = df_X.dot(corr)\n",
      "\n",
      "    \n",
      "    \n",
      "    \n",
      "    df_X['mean'] = df_X.apply(np.mean,axis=1,raw=True)\n",
      "    df_X['std'] = df_X.apply(np.std,axis=1,raw=True)\n",
      "    df_X['median'] = df_X.apply(np.median,axis=1,raw=True)\n",
      "    df_X['amax'] = df_X.apply(np.amax,axis=1,raw=True)\n",
      "    df_X['amin'] = df_X.apply(np.amin,axis=1,raw=True)\n",
      "\n",
      "\n",
      "    df_X['ptp'] = df_X.apply(np.ptp,axis=1)\n",
      "    \n",
      "    \n",
      "    df_X = pd.concat([df_X,\n",
      "                      df_tmp,\n",
      "                      df_tmp_2,\n",
      "                      #df_tmp_3,\n",
      "                      df_tmp_4,\n",
      "                      df_tmp_5,\n",
      "                      df_tmp_6,\n",
      "                      #df_tmp_7,\n",
      "                      #df_tmp_8,\n",
      "                      #df_tmp_9,\n",
      "              df_tmp_11,\n",
      "                      df_test\n",
      "                      ],axis=1)\n",
      "        \n",
      "    X = df_X.values.astype(np.float32)\n",
      "\n",
      "    if shuffle_data == True:\n",
      "        z = shuffle(X.T)\n",
      "        X = z.T\n",
      "    print('shape')\n",
      "    print(X.shape)\n",
      "    \n",
      "    slice_length = round(X.shape[1]/how_many_slices)\n",
      "    print(slice_length, how_many_slices)\n",
      "    X = X[:,which_slice*slice_length:(which_slice+1)*slice_length]\n",
      "    \n",
      "    print('shape new')\n",
      "    print(X.shape)\n",
      "    end = time.clock()\n",
      "\n",
      "    return X\n",
      "\n",
      "\n",
      "\n",
      "from sklearn.metrics import log_loss\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def get_score(clf, features = True,which_slice = 0,how_many_slices = 1,shuffle_data = False):\n",
      "    \"\"\"computes a cross validation score\n",
      "    \n",
      "    takes all keywords from generate_features\"\"\"\n",
      "    \n",
      "    start = time.clock()\n",
      "    X,y = load_data()\n",
      "    if features == True:\n",
      "        X = generate_features(X,which_slice=which_slice,how_many_slices=how_many_slices ,shuffle_data=shuffle_data)\n",
      "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y, test_size=0.2)\n",
      "    #print(y_train)\n",
      "    clf.fit(X_train,y_train)\n",
      "    outcome = clf.predict_proba(X_test)\n",
      "    end = time.clock()\n",
      "    print('SCORE: ' , log_loss(y_test,outcome), ' time: ',end-start)\n",
      "    \n",
      "def get_score2(clf,features = True,which_slice = 1,how_many_slices = 5,shuffle_data = False):\n",
      "    X,y = load_data()\n",
      "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y, test_size=0.2)#, random_state=0)\n",
      "    clf.fit(X_train,y_train)\n",
      "    outcome = clf.predict_proba(X_test)\n",
      "    print(log_loss(y_test,outcome))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def make_guess_csv(clf,features =True,name = 'test',which_slice = 0,how_many_slices = 1,shuffle_data = False):\n",
      "    \"\"\"generates a csv file containing the output from one classifier.\n",
      "    index starts at 0, so no submittable file is created (was necessary in an older version of combine_results, \n",
      "    not sure if it still is)\n",
      "    \"\"\"\n",
      "    start = time.clock()\n",
      "    X_test,y_test = load_data()\n",
      "    X = load_data(train=False)\n",
      "    if features == True:\n",
      "        X = generate_features(X,which_slice=which_slice ,how_many_slices=how_many_slices ,shuffle_data=shuffle_data)\n",
      "        X_test = generate_features(X_test,which_slice=which_slice,how_many_slices=how_many_slices ,shuffle_data=shuffle_data )\n",
      "\n",
      "    \n",
      "    clf.fit(X_test,y_test)\n",
      "    output = clf.predict_proba(X)\n",
      "    \n",
      "    \n",
      "    cols = ['Class_1',\n",
      "      'Class_2',\n",
      "      'Class_3',\n",
      "      'Class_4',\n",
      "      'Class_5',\n",
      "      'Class_6',\n",
      "      'Class_7',\n",
      "      'Class_8',\n",
      "      'Class_9']\n",
      "    df_write = pd.DataFrame(output)\n",
      "    shuf = '_noshuf_'\n",
      "    if shuffle_data==True:\n",
      "        shuf = '_shufled_'\n",
      "    slices = 'num_slice_' + str(how_many_slices)\n",
      "    which_clf = clf\n",
      "    num_slice = 'slice_num_' + str(which_slice)\n",
      "    clf = str(clf)\n",
      "    \n",
      "    file_name = 'Pikki' + name  +num_slice + slices + shuf + '.csv'\n",
      "    print('written to ' + file_name)\n",
      "    df_write.to_csv(file_name,header = cols,index_label = ['id'])\n",
      "    end = time.clock()\n",
      "    print(end-start)\n",
      "    identifier = name  +num_slice + slices + shuf\n",
      "    return identifier\n",
      "    \n",
      "\n",
      "\n",
      "def load_all_dfs(clf_list = ['test_small','test2_small']):#,'rt_small']):\n",
      "    \"\"\"loads all the csv files that end with specification in clf_list\n",
      "    in multiindex DataFrame. first row is specification, second is index\n",
      "    \n",
      "    helper for combine_results and plot_bias\n",
      "    \"\"\"\n",
      "    \n",
      "    start = time.clock()\n",
      "    print('loading data')\n",
      "    first_clf = clf_list[0]\n",
      "    df = pd.read_csv('Pikki'+first_clf+'.csv')\n",
      "    df['df'] = first_clf\n",
      "\n",
      "    df = df.set_index(['id','df'])\n",
      "\n",
      "    for clf in clf_list[1:]:\n",
      "        file_name = 'Pikki' + clf + '.csv'\n",
      "        df_tmp = pd.read_csv(file_name)\n",
      "        df_tmp['df'] = clf\n",
      "\n",
      "        df_tmp = df_tmp.set_index(['id','df'])\n",
      "\n",
      "        df = pd.concat([df,df_tmp])\n",
      "\n",
      "        \n",
      "    df['std'] = df.apply(np.std,axis=1,raw = True)\n",
      "    end = time.clock()\n",
      "    print(end-start)\n",
      "    return df#.swaplevel(0,1)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def combine_results(voting = 'hard',clf_list = ['test_small','test2_small']):\n",
      "    \"\"\"combines two or more classifier outputs. \n",
      "    by now only uses hard voting by standard deviation \n",
      "    (more std means higher values which ~ means higher confidence)\n",
      "    other measures welcome\n",
      "    \n",
      "    creates both a submittable file (\"combined ...\")\n",
      "    and a file that can be used for combination with other classifiers\n",
      "    \"\"\"\n",
      "    \n",
      "    start = time.clock()\n",
      "    df = load_all_dfs(clf_list)\n",
      "\n",
      "    print('combining the data and voting ', voting)\n",
      "\n",
      "    if voting == 'hard':\n",
      "        print('voting')\n",
      "\n",
      "        label_tupel_list = list(df.groupby(level=['id'])['std'].idxmax())#idmax \n",
      "        num_samples = len(label_tupel_list)\n",
      "        index = [label_tupel_list[i][0] for i in range(num_samples)]\n",
      "        df.index\n",
      "        time_need = []\n",
      "        t2 = 0\n",
      "\n",
      "        print(\"doing god's work\")\n",
      "        df_new = df.ix[index]\n",
      "        df_new = df.ix[label_tupel_list]\n",
      "        \n",
      "     #### new###   \n",
      "    if voting == 'soft':\n",
      "        clsfr1 = clf_list[0]\n",
      "        clsfr2 = clf_list[1]\n",
      "        print('softvoting')\n",
      "        df = df.reset_index()\n",
      "        df1 = df[df.df==clsfr1]\n",
      "        df2 = df[df.df==clsfr2]\n",
      "        std1 = df1['std']\n",
      "        std2 = df2['std']\n",
      "        df1 = df1.drop('id',axis=1)\n",
      "        df2 = df2.drop('id',axis=1)\n",
      "        df1 = df1.drop('df',axis=1)\n",
      "        df2 = df2.drop('df',axis=1)\n",
      "        df1 = df1.drop('std',axis=1)\n",
      "        df2 = df2.drop('std',axis=1)\n",
      "\n",
      "        df1_new = df1.pow(std1.values,axis = 0)#pd.DataFrame(df1.values**std1.values, columns = df1.columns, index=df1.index)\n",
      "        df2_new = df2.pow(std2.values,axis=0)#pd.DataFrame(df2.values**std2.values, columns = df2.columns, index=df2.index)\n",
      "        df_new = pd.DataFrame(df1.values*df2.values, columns=df1.columns, index=df1.index)\n",
      "\n",
      "  ####endnew              \n",
      "        \n",
      "    end = time.clock()\n",
      "    print('done', end-start)\n",
      "    #return df_new\n",
      "   \n",
      "    \n",
      "    cols = ['Class_1',\n",
      "      'Class_2',\n",
      "      'Class_3',\n",
      "      'Class_4',\n",
      "      'Class_5',\n",
      "      'Class_6',\n",
      "      'Class_7',\n",
      "      'Class_8',\n",
      "      'Class_9']\n",
      "    try:\n",
      "        df_new2 = df_new.reset_index()\n",
      "\n",
      "        del df_new2['std']\n",
      "        del df_new2['id']\n",
      "        del df_new2['df']\n",
      "    except:\n",
      "        df_new2 = df_new\n",
      "\n",
      "    print('zero')\n",
      "    try:\n",
      "     print('first')\n",
      "     clf_names = 'with_'\n",
      "     print('second')\n",
      "     for i in range(len(clf_list)):\n",
      "         print(clf_list[i])\n",
      "         clf_names = clf_names + '_' +  clf_list[i]\n",
      "            \n",
      "     df_new2.to_csv('Pikki'+clf_names+ '.csv',header = cols,index_label = ['id'])\n",
      "       \n",
      "     df_new2.index +=1\n",
      "\n",
      "     print('written to')\n",
      "     print('Pikki'+clf_names+ '.csv')\n",
      "     \n",
      "     df_new2.to_csv('combined_Pikki'+clf_names+ '.csv',header = cols,index_label = ['id'])\n",
      "    except:\n",
      "        df_new2.to_csv('combined_Pikki.csv',header = cols,index_label = ['id'])\n",
      "    return df_new    \n",
      "\n",
      "\n",
      "\n",
      "def plot_bias(clf_list = ['test_small','rt_small','test2_small'],return_df = False,XKCD = False):\n",
      "    \"\"\"plots some differences between two output files.\n",
      "    right now plots for every class and every classifier\n",
      "    \n",
      "    mean\n",
      "    max\n",
      "    std\n",
      "    diff(clfx-clfy)\n",
      "    \n",
      "    plt.xkcd() is optional.\n",
      "    \"\"\"\n",
      "    if XKCD == True:\n",
      "        plt.xkcd()\n",
      "    print('damn')\n",
      "    df = load_all_dfs(clf_list)\n",
      "    df = df.swaplevel(0,1)\n",
      "    del df['std']\n",
      "    df.hist()\n",
      "    plt.figure()\n",
      "\n",
      "    for clf in clf_list:\n",
      "        df.ix[clf].mean().plot(label = clf,figsize=(16, 4))\n",
      "    plt.legend(loc='upper right')\n",
      "    plt.title('mean')\n",
      "    plt.figure()\n",
      "    \n",
      "   # c = df.columns\n",
      "    for clf in clf_list:\n",
      "        #df[c[1:]].ix[clf].max().plot(label = clf,figsize=(16, 4))\n",
      "        df.ix[clf].max().plot(label = clf,figsize=(16, 4))\n",
      "    plt.legend(loc='upper right')\n",
      "    plt.title('max')\n",
      "    \n",
      "    plt.figure()\n",
      "    for clf in clf_list:\n",
      "        df.ix[clf].std().plot(label = clf,figsize=(16, 4))\n",
      "\n",
      "        \n",
      "    plt.legend(loc='upper right')\n",
      "    plt.title('std')\n",
      "    plt.figure()\n",
      "    used_list = []\n",
      "    for clf in clf_list:\n",
      "        for clf2 in clf_list:\n",
      "            if (clf != clf2) and ({clf,clf2} not in used_list):\n",
      "                diff = ((df.ix[clf] - df.ix[clf2])**2)**(1/2)\n",
      "                diff.mean().plot(label = clf+' - ' +clf2,figsize=(16, 4))\n",
      "                used_list.append({clf,clf2})\n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "    plt.legend(loc='upper right')\n",
      "    plt.title('difference')\n",
      "    print('damnover')\n",
      "    if return_df == True:\n",
      "     return df\n",
      "    \n",
      "def example():\n",
      "    \"\"\"example on how to run this\"\"\"\n",
      "    #generate a classifier\n",
      "    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
      "    clf = RandomForestClassifier(n_estimators=4,n_jobs=-1)\n",
      "    clf2 = GradientBoostingClassifier(n_estimators = 1)\n",
      "    #make guess csv\n",
      "    n1 = make_guess_csv(clf,name='example')\n",
      "    n2 = make_guess_csv(clf2,name='example_2')\n",
      "    #combine results\n",
      "    print(n1,n2)\n",
      "    combine_results(clf_list=[n1,n2])\n",
      "    #plot the stuff\n",
      "    plot_bias([n1,n2],XKCD = True)\n",
      "    \n",
      "#noclue if this is necessary. If somebody has better information, please let me know\n",
      "#def main():\n",
      "#    example()\n",
      "#if __name__ == \"__main__\":\n",
      "#    main()\n",
      "\n",
      "\n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = load_all_dfs()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading data\n",
        "0.012886999999999205\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = df.reset_index()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b = a[a.df=='test_small']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = a[a.df=='test2_small']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b = b.drop('id',axis=1)\n",
      "c = c.drop('id',axis=1)\n",
      "b = b.drop('df',axis=1)\n",
      "c = c.drop('df',axis=1)\n",
      "d = pd.DataFrame(b.values*c.values, columns=b.columns, index=b.index)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stdb = b['std']\n",
      "b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Class_1</th>\n",
        "      <th>Class_2</th>\n",
        "      <th>Class_3</th>\n",
        "      <th>Class_4</th>\n",
        "      <th>Class_5</th>\n",
        "      <th>Class_6</th>\n",
        "      <th>Class_7</th>\n",
        "      <th>Class_8</th>\n",
        "      <th>Class_9</th>\n",
        "      <th>std</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> 0.000896</td>\n",
        "      <td> 0.000896</td>\n",
        "      <td> 0.001208</td>\n",
        "      <td> 0.000694</td>\n",
        "      <td> 0.000535</td>\n",
        "      <td> 0.994089</td>\n",
        "      <td> 0.000595</td>\n",
        "      <td> 0.000559</td>\n",
        "      <td> 0.000767</td>\n",
        "      <td> 0.312170</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> 0.018448</td>\n",
        "      <td> 0.018448</td>\n",
        "      <td> 0.769795</td>\n",
        "      <td> 0.057057</td>\n",
        "      <td> 0.032740</td>\n",
        "      <td> 0.004062</td>\n",
        "      <td> 0.024014</td>\n",
        "      <td> 0.028082</td>\n",
        "      <td> 0.034563</td>\n",
        "      <td> 0.233781</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> 0.022536</td>\n",
        "      <td> 0.022536</td>\n",
        "      <td> 0.640178</td>\n",
        "      <td> 0.150347</td>\n",
        "      <td> 0.042212</td>\n",
        "      <td> 0.005030</td>\n",
        "      <td> 0.032859</td>\n",
        "      <td> 0.034543</td>\n",
        "      <td> 0.028615</td>\n",
        "      <td> 0.192031</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> 0.267139</td>\n",
        "      <td> 0.267139</td>\n",
        "      <td> 0.042531</td>\n",
        "      <td> 0.029113</td>\n",
        "      <td> 0.008631</td>\n",
        "      <td> 0.001383</td>\n",
        "      <td> 0.017151</td>\n",
        "      <td> 0.165084</td>\n",
        "      <td> 0.459062</td>\n",
        "      <td> 0.152067</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> 0.002197</td>\n",
        "      <td> 0.002197</td>\n",
        "      <td> 0.002475</td>\n",
        "      <td> 0.001511</td>\n",
        "      <td> 0.001331</td>\n",
        "      <td> 0.000222</td>\n",
        "      <td> 0.986837</td>\n",
        "      <td> 0.001628</td>\n",
        "      <td> 0.002289</td>\n",
        "      <td> 0.309589</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> 0.000800</td>\n",
        "      <td> 0.000800</td>\n",
        "      <td> 0.001000</td>\n",
        "      <td> 0.000807</td>\n",
        "      <td> 0.000539</td>\n",
        "      <td> 0.000110</td>\n",
        "      <td> 0.994270</td>\n",
        "      <td> 0.000835</td>\n",
        "      <td> 0.000974</td>\n",
        "      <td> 0.312239</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> 0.000931</td>\n",
        "      <td> 0.000931</td>\n",
        "      <td> 0.001478</td>\n",
        "      <td> 0.000838</td>\n",
        "      <td> 0.001575</td>\n",
        "      <td> 0.988156</td>\n",
        "      <td> 0.004653</td>\n",
        "      <td> 0.000828</td>\n",
        "      <td> 0.000938</td>\n",
        "      <td> 0.310071</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> 0.005271</td>\n",
        "      <td> 0.005271</td>\n",
        "      <td> 0.790807</td>\n",
        "      <td> 0.128623</td>\n",
        "      <td> 0.032465</td>\n",
        "      <td> 0.003319</td>\n",
        "      <td> 0.010724</td>\n",
        "      <td> 0.009953</td>\n",
        "      <td> 0.009499</td>\n",
        "      <td> 0.243387</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> 0.004315</td>\n",
        "      <td> 0.004315</td>\n",
        "      <td> 0.009395</td>\n",
        "      <td> 0.006988</td>\n",
        "      <td> 0.004000</td>\n",
        "      <td> 0.000546</td>\n",
        "      <td> 0.960005</td>\n",
        "      <td> 0.004564</td>\n",
        "      <td> 0.005478</td>\n",
        "      <td> 0.300153</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 0.024175</td>\n",
        "      <td> 0.024175</td>\n",
        "      <td> 0.009300</td>\n",
        "      <td> 0.007633</td>\n",
        "      <td> 0.003708</td>\n",
        "      <td> 0.001363</td>\n",
        "      <td> 0.012453</td>\n",
        "      <td> 0.026567</td>\n",
        "      <td> 0.905032</td>\n",
        "      <td> 0.280265</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 0.012974</td>\n",
        "      <td> 0.012974</td>\n",
        "      <td> 0.787314</td>\n",
        "      <td> 0.073439</td>\n",
        "      <td> 0.070193</td>\n",
        "      <td> 0.001919</td>\n",
        "      <td> 0.012657</td>\n",
        "      <td> 0.013631</td>\n",
        "      <td> 0.012411</td>\n",
        "      <td> 0.240477</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 0.037720</td>\n",
        "      <td> 0.037720</td>\n",
        "      <td> 0.032725</td>\n",
        "      <td> 0.021463</td>\n",
        "      <td> 0.014726</td>\n",
        "      <td> 0.003295</td>\n",
        "      <td> 0.042979</td>\n",
        "      <td> 0.033618</td>\n",
        "      <td> 0.674246</td>\n",
        "      <td> 0.203440</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> 0.103622</td>\n",
        "      <td> 0.103622</td>\n",
        "      <td> 0.015009</td>\n",
        "      <td> 0.011155</td>\n",
        "      <td> 0.006246</td>\n",
        "      <td> 0.001828</td>\n",
        "      <td> 0.092928</td>\n",
        "      <td> 0.012691</td>\n",
        "      <td> 0.036264</td>\n",
        "      <td> 0.041699</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> 0.023203</td>\n",
        "      <td> 0.023203</td>\n",
        "      <td> 0.004952</td>\n",
        "      <td> 0.004150</td>\n",
        "      <td> 0.002365</td>\n",
        "      <td> 0.000488</td>\n",
        "      <td> 0.017021</td>\n",
        "      <td> 0.009279</td>\n",
        "      <td> 0.932341</td>\n",
        "      <td> 0.289796</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td> 0.004346</td>\n",
        "      <td> 0.004346</td>\n",
        "      <td> 0.160047</td>\n",
        "      <td> 0.767141</td>\n",
        "      <td> 0.040202</td>\n",
        "      <td> 0.000888</td>\n",
        "      <td> 0.005558</td>\n",
        "      <td> 0.006784</td>\n",
        "      <td> 0.007657</td>\n",
        "      <td> 0.236989</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td> 0.008704</td>\n",
        "      <td> 0.008704</td>\n",
        "      <td> 0.767445</td>\n",
        "      <td> 0.160969</td>\n",
        "      <td> 0.015394</td>\n",
        "      <td> 0.001609</td>\n",
        "      <td> 0.010230</td>\n",
        "      <td> 0.013302</td>\n",
        "      <td> 0.011782</td>\n",
        "      <td> 0.236877</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "     Class_1   Class_2   Class_3   Class_4   Class_5   Class_6   Class_7  \\\n",
        "0   0.000896  0.000896  0.001208  0.000694  0.000535  0.994089  0.000595   \n",
        "1   0.018448  0.018448  0.769795  0.057057  0.032740  0.004062  0.024014   \n",
        "2   0.022536  0.022536  0.640178  0.150347  0.042212  0.005030  0.032859   \n",
        "3   0.267139  0.267139  0.042531  0.029113  0.008631  0.001383  0.017151   \n",
        "4   0.002197  0.002197  0.002475  0.001511  0.001331  0.000222  0.986837   \n",
        "5   0.000800  0.000800  0.001000  0.000807  0.000539  0.000110  0.994270   \n",
        "6   0.000931  0.000931  0.001478  0.000838  0.001575  0.988156  0.004653   \n",
        "7   0.005271  0.005271  0.790807  0.128623  0.032465  0.003319  0.010724   \n",
        "8   0.004315  0.004315  0.009395  0.006988  0.004000  0.000546  0.960005   \n",
        "9   0.024175  0.024175  0.009300  0.007633  0.003708  0.001363  0.012453   \n",
        "10  0.012974  0.012974  0.787314  0.073439  0.070193  0.001919  0.012657   \n",
        "11  0.037720  0.037720  0.032725  0.021463  0.014726  0.003295  0.042979   \n",
        "12  0.103622  0.103622  0.015009  0.011155  0.006246  0.001828  0.092928   \n",
        "13  0.023203  0.023203  0.004952  0.004150  0.002365  0.000488  0.017021   \n",
        "14  0.004346  0.004346  0.160047  0.767141  0.040202  0.000888  0.005558   \n",
        "15  0.008704  0.008704  0.767445  0.160969  0.015394  0.001609  0.010230   \n",
        "\n",
        "     Class_8   Class_9       std  \n",
        "0   0.000559  0.000767  0.312170  \n",
        "1   0.028082  0.034563  0.233781  \n",
        "2   0.034543  0.028615  0.192031  \n",
        "3   0.165084  0.459062  0.152067  \n",
        "4   0.001628  0.002289  0.309589  \n",
        "5   0.000835  0.000974  0.312239  \n",
        "6   0.000828  0.000938  0.310071  \n",
        "7   0.009953  0.009499  0.243387  \n",
        "8   0.004564  0.005478  0.300153  \n",
        "9   0.026567  0.905032  0.280265  \n",
        "10  0.013631  0.012411  0.240477  \n",
        "11  0.033618  0.674246  0.203440  \n",
        "12  0.012691  0.036264  0.041699  \n",
        "13  0.009279  0.932341  0.289796  \n",
        "14  0.006784  0.007657  0.236989  \n",
        "15  0.013302  0.011782  0.236877  "
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stdb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 75,
       "text": [
        "0     0.312170\n",
        "1     0.233781\n",
        "2     0.192031\n",
        "3     0.152067\n",
        "4     0.309589\n",
        "5     0.312239\n",
        "6     0.310071\n",
        "7     0.243387\n",
        "8     0.300153\n",
        "9     0.280265\n",
        "10    0.240477\n",
        "11    0.203440\n",
        "12    0.041699\n",
        "13    0.289796\n",
        "14    0.236989\n",
        "15    0.236877\n",
        "Name: std, dtype: float64"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = pd.DataFrame(b.values*c.values, columns=b.columns, index=b.index)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Class_1</th>\n",
        "      <th>Class_2</th>\n",
        "      <th>Class_3</th>\n",
        "      <th>Class_4</th>\n",
        "      <th>Class_5</th>\n",
        "      <th>Class_6</th>\n",
        "      <th>Class_7</th>\n",
        "      <th>Class_8</th>\n",
        "      <th>Class_9</th>\n",
        "      <th>std</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> 0.000012</td>\n",
        "      <td> 0.000705</td>\n",
        "      <td> 0.000089</td>\n",
        "      <td> 0.000049</td>\n",
        "      <td> 0.000001</td>\n",
        "      <td> 0.012582</td>\n",
        "      <td> 0.000008</td>\n",
        "      <td> 0.000007</td>\n",
        "      <td> 0.000012</td>\n",
        "      <td> 0.075035</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> 0.000696</td>\n",
        "      <td> 0.000604</td>\n",
        "      <td> 0.016522</td>\n",
        "      <td> 0.000840</td>\n",
        "      <td> 0.000108</td>\n",
        "      <td> 0.000175</td>\n",
        "      <td> 0.000807</td>\n",
        "      <td> 0.018934</td>\n",
        "      <td> 0.004812</td>\n",
        "      <td> 0.047340</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> 0.002335</td>\n",
        "      <td> 0.000338</td>\n",
        "      <td> 0.007141</td>\n",
        "      <td> 0.000939</td>\n",
        "      <td> 0.000077</td>\n",
        "      <td> 0.000467</td>\n",
        "      <td> 0.000417</td>\n",
        "      <td> 0.001253</td>\n",
        "      <td> 0.020610</td>\n",
        "      <td> 0.041921</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> 0.006198</td>\n",
        "      <td> 0.001323</td>\n",
        "      <td> 0.000176</td>\n",
        "      <td> 0.000069</td>\n",
        "      <td> 0.000004</td>\n",
        "      <td> 0.000024</td>\n",
        "      <td> 0.000159</td>\n",
        "      <td> 0.153914</td>\n",
        "      <td> 0.002847</td>\n",
        "      <td> 0.044165</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> 0.000010</td>\n",
        "      <td> 0.000352</td>\n",
        "      <td> 0.001899</td>\n",
        "      <td> 0.000061</td>\n",
        "      <td> 0.000001</td>\n",
        "      <td> 0.000001</td>\n",
        "      <td> 0.006694</td>\n",
        "      <td> 0.000012</td>\n",
        "      <td> 0.000017</td>\n",
        "      <td> 0.073323</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> 0.000007</td>\n",
        "      <td> 0.000614</td>\n",
        "      <td> 0.000161</td>\n",
        "      <td> 0.000012</td>\n",
        "      <td> 0.000001</td>\n",
        "      <td> 0.000001</td>\n",
        "      <td> 0.013226</td>\n",
        "      <td> 0.000010</td>\n",
        "      <td> 0.000010</td>\n",
        "      <td> 0.073935</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> 0.000005</td>\n",
        "      <td> 0.000482</td>\n",
        "      <td> 0.000599</td>\n",
        "      <td> 0.000019</td>\n",
        "      <td> 0.000002</td>\n",
        "      <td> 0.020800</td>\n",
        "      <td> 0.000043</td>\n",
        "      <td> 0.000008</td>\n",
        "      <td> 0.000008</td>\n",
        "      <td> 0.058697</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> 0.000054</td>\n",
        "      <td> 0.001738</td>\n",
        "      <td> 0.483915</td>\n",
        "      <td> 0.000688</td>\n",
        "      <td> 0.000068</td>\n",
        "      <td> 0.000031</td>\n",
        "      <td> 0.000084</td>\n",
        "      <td> 0.000105</td>\n",
        "      <td> 0.000122</td>\n",
        "      <td> 0.049523</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> 0.000011</td>\n",
        "      <td> 0.004046</td>\n",
        "      <td> 0.000278</td>\n",
        "      <td> 0.000079</td>\n",
        "      <td> 0.000002</td>\n",
        "      <td> 0.000003</td>\n",
        "      <td> 0.003452</td>\n",
        "      <td> 0.000021</td>\n",
        "      <td> 0.000024</td>\n",
        "      <td> 0.087750</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 0.000160</td>\n",
        "      <td> 0.021719</td>\n",
        "      <td> 0.000349</td>\n",
        "      <td> 0.000103</td>\n",
        "      <td> 0.000008</td>\n",
        "      <td> 0.000011</td>\n",
        "      <td> 0.000140</td>\n",
        "      <td> 0.000325</td>\n",
        "      <td> 0.009155</td>\n",
        "      <td> 0.078055</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 0.000297</td>\n",
        "      <td> 0.004590</td>\n",
        "      <td> 0.229320</td>\n",
        "      <td> 0.014907</td>\n",
        "      <td> 0.000322</td>\n",
        "      <td> 0.000044</td>\n",
        "      <td> 0.000793</td>\n",
        "      <td> 0.000260</td>\n",
        "      <td> 0.000249</td>\n",
        "      <td> 0.030612</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 0.002507</td>\n",
        "      <td> 0.001891</td>\n",
        "      <td> 0.000943</td>\n",
        "      <td> 0.000284</td>\n",
        "      <td> 0.000056</td>\n",
        "      <td> 0.000259</td>\n",
        "      <td> 0.002125</td>\n",
        "      <td> 0.021472</td>\n",
        "      <td> 0.047750</td>\n",
        "      <td> 0.038266</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> 0.000135</td>\n",
        "      <td> 0.000735</td>\n",
        "      <td> 0.000044</td>\n",
        "      <td> 0.000012</td>\n",
        "      <td> 0.000001</td>\n",
        "      <td> 0.001796</td>\n",
        "      <td> 0.000163</td>\n",
        "      <td> 0.000027</td>\n",
        "      <td> 0.000046</td>\n",
        "      <td> 0.012844</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> 0.000025</td>\n",
        "      <td> 0.000024</td>\n",
        "      <td> 0.000004</td>\n",
        "      <td> 0.000002</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000485</td>\n",
        "      <td> 0.000014</td>\n",
        "      <td> 0.000012</td>\n",
        "      <td> 0.000637</td>\n",
        "      <td> 0.090418</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td> 0.000023</td>\n",
        "      <td> 0.002522</td>\n",
        "      <td> 0.030302</td>\n",
        "      <td> 0.146782</td>\n",
        "      <td> 0.000047</td>\n",
        "      <td> 0.000006</td>\n",
        "      <td> 0.000067</td>\n",
        "      <td> 0.000051</td>\n",
        "      <td> 0.000047</td>\n",
        "      <td> 0.043158</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td> 0.000038</td>\n",
        "      <td> 0.003545</td>\n",
        "      <td> 0.425006</td>\n",
        "      <td> 0.000393</td>\n",
        "      <td> 0.000016</td>\n",
        "      <td> 0.000009</td>\n",
        "      <td> 0.000175</td>\n",
        "      <td> 0.000065</td>\n",
        "      <td> 0.000043</td>\n",
        "      <td> 0.047495</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "     Class_1   Class_2   Class_3   Class_4   Class_5   Class_6   Class_7  \\\n",
        "0   0.000012  0.000705  0.000089  0.000049  0.000001  0.012582  0.000008   \n",
        "1   0.000696  0.000604  0.016522  0.000840  0.000108  0.000175  0.000807   \n",
        "2   0.002335  0.000338  0.007141  0.000939  0.000077  0.000467  0.000417   \n",
        "3   0.006198  0.001323  0.000176  0.000069  0.000004  0.000024  0.000159   \n",
        "4   0.000010  0.000352  0.001899  0.000061  0.000001  0.000001  0.006694   \n",
        "5   0.000007  0.000614  0.000161  0.000012  0.000001  0.000001  0.013226   \n",
        "6   0.000005  0.000482  0.000599  0.000019  0.000002  0.020800  0.000043   \n",
        "7   0.000054  0.001738  0.483915  0.000688  0.000068  0.000031  0.000084   \n",
        "8   0.000011  0.004046  0.000278  0.000079  0.000002  0.000003  0.003452   \n",
        "9   0.000160  0.021719  0.000349  0.000103  0.000008  0.000011  0.000140   \n",
        "10  0.000297  0.004590  0.229320  0.014907  0.000322  0.000044  0.000793   \n",
        "11  0.002507  0.001891  0.000943  0.000284  0.000056  0.000259  0.002125   \n",
        "12  0.000135  0.000735  0.000044  0.000012  0.000001  0.001796  0.000163   \n",
        "13  0.000025  0.000024  0.000004  0.000002  0.000000  0.000485  0.000014   \n",
        "14  0.000023  0.002522  0.030302  0.146782  0.000047  0.000006  0.000067   \n",
        "15  0.000038  0.003545  0.425006  0.000393  0.000016  0.000009  0.000175   \n",
        "\n",
        "     Class_8   Class_9       std  \n",
        "0   0.000007  0.000012  0.075035  \n",
        "1   0.018934  0.004812  0.047340  \n",
        "2   0.001253  0.020610  0.041921  \n",
        "3   0.153914  0.002847  0.044165  \n",
        "4   0.000012  0.000017  0.073323  \n",
        "5   0.000010  0.000010  0.073935  \n",
        "6   0.000008  0.000008  0.058697  \n",
        "7   0.000105  0.000122  0.049523  \n",
        "8   0.000021  0.000024  0.087750  \n",
        "9   0.000325  0.009155  0.078055  \n",
        "10  0.000260  0.000249  0.030612  \n",
        "11  0.021472  0.047750  0.038266  \n",
        "12  0.000027  0.000046  0.012844  \n",
        "13  0.000012  0.000637  0.090418  \n",
        "14  0.000051  0.000047  0.043158  \n",
        "15  0.000065  0.000043  0.047495  "
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combine_results(voting='soft')#,clf_list=['test52','test49'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading data\n",
        "0.021243000000005452\n",
        "combining the data and voting  soft\n",
        "softvoting\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "Wrong number of items passed 16, placement implies 9",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-95-04a1a5a5f51f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcombine_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'soft'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#,clf_list=['test52','test49'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-94-6ffff8d88796>\u001b[0m in \u001b[0;36mcombine_results\u001b[1;34m(voting, clf_list)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'std'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[0mdf1_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#pd.DataFrame(df1.values**std1.values, columns = df1.columns, index=df1.index)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[0mdf2_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#pd.DataFrame(df2.values**std2.values, columns = df2.columns, index=df2.index)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mdf_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/thomas/anaconda3/lib/python3.4/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[0;32m    788\u001b[0m                     \u001b[1;31m# casted = self._constructor_sliced(other,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m                     \u001b[1;31m#                                   index=self.columns)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m                     \u001b[0mcasted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    791\u001b[0m                 return self._combine_series(casted, na_op, fill_value,\n\u001b[0;32m    792\u001b[0m                                             axis, level)\n",
        "\u001b[1;32m/home/thomas/anaconda3/lib/python3.4/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    229\u001b[0m                                        raise_cast_failure=True)\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/thomas/anaconda3/lib/python3.4/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, block, axis, do_integrity_check, fastpath)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             block = make_block(block,\n\u001b[0;32m   3074\u001b[0m                                \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m                                ndim=1, fastpath=True)\n\u001b[0m\u001b[0;32m   3076\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/thomas/anaconda3/lib/python3.4/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mmake_block\u001b[1;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m     return klass(values, ndim=ndim, fastpath=fastpath,\n\u001b[1;32m-> 1847\u001b[1;33m                  placement=placement)\n\u001b[0m\u001b[0;32m   1848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/thomas/anaconda3/lib/python3.4/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, placement, ndim, fastpath)\u001b[0m\n\u001b[0;32m     70\u001b[0m             raise ValueError('Wrong number of items passed %d,'\n\u001b[0;32m     71\u001b[0m                              ' placement implies %d' % (\n\u001b[1;32m---> 72\u001b[1;33m                                  len(self.values), len(self.mgr_locs)))\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: Wrong number of items passed 16, placement implies 9"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}